<!doctype html><html lang=en dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Contents # OWASP Top 10 for Large Language Model Applications Prompt Injection Articles Prompt Injection Videos Prompt Injection CTF LLM Hacker Handbook Videos AI Attack Surface Map Research Papers OWASP Top 10 for Large Language Model Applications # https://owasp.org/www-project-top-10-for-large-language-model-applications/ Prompt Injection Articles # https://josephthacker.com/ai/2023/04/19/prompt-injection-and-mitigations.html https://josephthacker.com/ai/2023/08/25/prompt-injection-primer.html https://research.nccgroup.com/2022/12/05/exploring-prompt-injection-attacks/ https://www.lakera.ai/insights/what-is-prompt-injection Prompt Injection Videos # Attacking LLM - Prompt Injection Accidental LLM Backdoor - Prompt Tricks Defending LLM - Prompt Injection Prompt Injection 101 - Understanding Security Risks in LLM Prompt Injection CTF # GPT Prompt Attack Double Speak Chat LLM Hacker Handbook # https://doublespeak."><meta name=theme-color content="#FFFFFF"><meta name=color-scheme content="light dark"><meta property="og:title" content="Learning Process"><meta property="og:description" content="Contents # OWASP Top 10 for Large Language Model Applications Prompt Injection Articles Prompt Injection Videos Prompt Injection CTF LLM Hacker Handbook Videos AI Attack Surface Map Research Papers OWASP Top 10 for Large Language Model Applications # https://owasp.org/www-project-top-10-for-large-language-model-applications/ Prompt Injection Articles # https://josephthacker.com/ai/2023/04/19/prompt-injection-and-mitigations.html https://josephthacker.com/ai/2023/08/25/prompt-injection-primer.html https://research.nccgroup.com/2022/12/05/exploring-prompt-injection-attacks/ https://www.lakera.ai/insights/what-is-prompt-injection Prompt Injection Videos # Attacking LLM - Prompt Injection Accidental LLM Backdoor - Prompt Tricks Defending LLM - Prompt Injection Prompt Injection 101 - Understanding Security Risks in LLM Prompt Injection CTF # GPT Prompt Attack Double Speak Chat LLM Hacker Handbook # https://doublespeak."><meta property="og:type" content="article"><meta property="og:url" content="https://cyber-security.wiki/docs/machine-learning/learning/"><meta property="article:section" content="docs"><meta property="article:modified_time" content="2023-10-24T21:58:35+05:30"><title>Learning Process | Cyber Security Wiki</title>
<link rel=manifest href=/manifest.json><link rel=icon href=/favicon.png type=image/x-icon><link rel=stylesheet href=/book.min.565a95e2043493949e3fa72db3ec317e1e40f462858e732a1b18d1354e9c030c.css integrity="sha256-VlqV4gQ0k5SeP6cts+wxfh5A9GKFjnMqGxjRNU6cAww=" crossorigin=anonymous><script defer src=/flexsearch.min.js></script><script defer src=/en.search.min.85d49c67365ca09e655e30ae0818da92205aa8201c766ce75c990bf056ae3c06.js integrity="sha256-hdScZzZcoJ5lXjCuCBjakiBaqCAcdmznXJkL8FauPAY=" crossorigin=anonymous></script><script defer src=/sw.min.6f6f90fcb8eb1c49ec389838e6b801d0de19430b8e516902f8d75c3c8bd98739.js integrity="sha256-b2+Q/LjrHEnsOJg45rgB0N4ZQwuOUWkC+NdcPIvZhzk=" crossorigin=anonymous></script></head><body dir=ltr><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><img src=/logo.png alt=Logo><span>Cyber Security Wiki</span></a></h2><div class=book-search><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><ul><li><br><input type=checkbox id=section-3478c05c39c328756601a040a5f9b7dc class=toggle>
<label for=section-3478c05c39c328756601a040a5f9b7dc class="flex justify-between" style=font-weight:700><a role=button>Application Security</a></label><ul><li><br><input type=checkbox id=section-3d187f458be5e96a9f7134b06fcbe171 class=toggle>
<label for=section-3d187f458be5e96a9f7134b06fcbe171 class="flex justify-between" style=font-weight:700><a role=button>Thick Client</a></label><ul><li><a href=https://cyber-security.wiki/docs/application-security/thick-client/checklist/>Checklist</a></li><li><a href=https://cyber-security.wiki/docs/application-security/thick-client/learningprocess/>Learning Process</a></li><li><a href=https://cyber-security.wiki/docs/application-security/thick-client/tools/>Tools</a></li></ul></li><li><br><input type=checkbox id=section-305f8624390448e7b7dfdcd57bcf3063 class=toggle>
<label for=section-305f8624390448e7b7dfdcd57bcf3063 class="flex justify-between" style=font-weight:700><a role=button>Web</a></label><ul><li><a href=https://cyber-security.wiki/docs/application-security/web/charset-xss/>Charset XSS</a></li></ul></li></ul></li><li><br><input type=checkbox id=section-eddb28de10b6358a7d90165be197c24d class=toggle>
<label for=section-eddb28de10b6358a7d90165be197c24d class="flex justify-between" style=font-weight:700><a role=button>Cloud Security</a></label><ul></ul></li><li><br><input type=checkbox id=section-80f73357b2e3d82569ab2419d9c8fd53 class=toggle>
<label for=section-80f73357b2e3d82569ab2419d9c8fd53 class="flex justify-between" style=font-weight:700><a role=button>DevSecOps</a></label><ul></ul></li><li><br><input type=checkbox id=section-f8c2cedc89ecea36eb3aab749e9d9325 class=toggle>
<label for=section-f8c2cedc89ecea36eb3aab749e9d9325 class="flex justify-between" style=font-weight:700><a role=button>Exploit Development</a></label><ul></ul></li><li><br><input type=checkbox id=section-ac63c4b6399921ce8f97ed202a2ebcb8 class=toggle>
<label for=section-ac63c4b6399921ce8f97ed202a2ebcb8 class="flex justify-between" style=font-weight:700><a role=button>IoT Security</a></label><ul></ul></li><li><br><input type=checkbox id=section-ff3f320cd65cf7b2cc2597d57706ff2e class=toggle checked>
<label for=section-ff3f320cd65cf7b2cc2597d57706ff2e class="flex justify-between" style=font-weight:700><a role=button>Machine Learning</a></label><ul><li><a href=https://cyber-security.wiki/docs/machine-learning/learning/ class=active>Learning Process</a></li></ul></li><li><br><input type=checkbox id=section-3110560962cac834dcd3aead95e804a4 class=toggle>
<label for=section-3110560962cac834dcd3aead95e804a4 class="flex justify-between" style=font-weight:700><a role=button>Network</a></label><ul></ul></li><li><br><input type=checkbox id=section-089d0b2a47920473e631158da2244e55 class=toggle>
<label for=section-089d0b2a47920473e631158da2244e55 class="flex justify-between" style=font-weight:700><a role=button>Red Teaming</a></label><ul></ul></li><li><br><input type=checkbox id=section-b1f24361e619eb3af87e435a6f600cbe class=toggle>
<label for=section-b1f24361e619eb3af87e435a6f600cbe class="flex justify-between" style=font-weight:700><a role=button>Threat Modelling</a></label><ul></ul></li></ul><hr><b><ul><li><a href=/contribute/>Contribute</a></li><li><a href=https://securecode.wiki target=_blank rel=noopener>Secure Code Wiki by Payatu</a></li></ul></b></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu>
</label><strong>Learning Process</strong>
<label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><ul><li><a href=#contents>Contents</a></li><li><a href=#owasp-top-10-for-large-language-model-applications>OWASP Top 10 for Large Language Model Applications</a></li><li><a href=#prompt-injection-articles>Prompt Injection Articles</a></li><li><a href=#prompt-injection-videos>Prompt Injection Videos</a></li><li><a href=#prompt-injection-ctf>Prompt Injection CTF</a></li><li><a href=#llm-hacker-handbook>LLM Hacker Handbook</a></li><li><a href=#videos>Videos</a></li><li><a href=#ai-attack-surface-map>AI Attack Surface Map</a></li><li><a href=#research-papers>Research Papers</a></li></ul></li></ul></nav></aside></header><article class=markdown><h2 id=contents>Contents
<a class=anchor href=#contents>#</a></h2><ul><li><a href=#OWASP-Top-10-for-Large-Language-Model-Applications>OWASP Top 10 for Large Language Model Applications</a><img src=/svg/icons8-external-link.svg style=height:15px></li><li><a href=#Prompt-Injection-Articles>Prompt Injection Articles</a><img src=/svg/icons8-external-link.svg style=height:15px></li><li><a href=#Prompt-Injection-Videos>Prompt Injection Videos</a><img src=/svg/icons8-external-link.svg style=height:15px></li><li><a href=#Prompt-Injection-CTF>Prompt Injection CTF</a><img src=/svg/icons8-external-link.svg style=height:15px></li><li><a href=#LLM-Hacker-Handbook>LLM Hacker Handbook</a><img src=/svg/icons8-external-link.svg style=height:15px></li><li><a href=#Videos>Videos</a><img src=/svg/icons8-external-link.svg style=height:15px></li><li><a href=#AI-Attack-Surface-Map>AI Attack Surface Map</a><img src=/svg/icons8-external-link.svg style=height:15px></li><li><a href=#Research-Papers>Research Papers</a><img src=/svg/icons8-external-link.svg style=height:15px></li></ul><h2 id=owasp-top-10-for-large-language-model-applications>OWASP Top 10 for Large Language Model Applications
<a class=anchor href=#owasp-top-10-for-large-language-model-applications>#</a></h2><ul><li><a href=https://owasp.org/www-project-top-10-for-large-language-model-applications/ target=_blank rel="noreferrer noopener nofollow">https://owasp.org/www-project-top-10-for-large-language-model-applications/</a><img src=/svg/icons8-external-link.svg style=height:15px></li></ul><h2 id=prompt-injection-articles>Prompt Injection Articles
<a class=anchor href=#prompt-injection-articles>#</a></h2><ul><li><a href=https://josephthacker.com/ai/2023/04/19/prompt-injection-and-mitigations.html target=_blank rel="noreferrer noopener nofollow">https://josephthacker.com/ai/2023/04/19/prompt-injection-and-mitigations.html</a><img src=/svg/icons8-external-link.svg style=height:15px></li><li><a href=https://josephthacker.com/ai/2023/08/25/prompt-injection-primer.html target=_blank rel="noreferrer noopener nofollow">https://josephthacker.com/ai/2023/08/25/prompt-injection-primer.html</a><img src=/svg/icons8-external-link.svg style=height:15px></li><li><a href=https://research.nccgroup.com/2022/12/05/exploring-prompt-injection-attacks/ target=_blank rel="noreferrer noopener nofollow">https://research.nccgroup.com/2022/12/05/exploring-prompt-injection-attacks/</a><img src=/svg/icons8-external-link.svg style=height:15px></li><li><a href=https://www.lakera.ai/insights/what-is-prompt-injection target=_blank rel="noreferrer noopener nofollow">https://www.lakera.ai/insights/what-is-prompt-injection</a><img src=/svg/icons8-external-link.svg style=height:15px></li></ul><h2 id=prompt-injection-videos>Prompt Injection Videos
<a class=anchor href=#prompt-injection-videos>#</a></h2><ul><li><a href="https://www.youtube.com/watch?v=Sv5OLj2nVAQ" target=_blank rel="noreferrer noopener nofollow">Attacking LLM - Prompt Injection</a><img src=/svg/icons8-external-link.svg style=height:15px></li><li><a href="https://www.youtube.com/watch?v=h74oXb4Kk8k" target=_blank rel="noreferrer noopener nofollow">Accidental LLM Backdoor - Prompt Tricks</a><img src=/svg/icons8-external-link.svg style=height:15px></li><li><a href="https://www.youtube.com/watch?v=VbNPZ1n6_vY" target=_blank rel="noreferrer noopener nofollow">Defending LLM - Prompt Injection</a><img src=/svg/icons8-external-link.svg style=height:15px></li><li><a href="https://www.youtube.com/watch?v=TDS6PGfniIU" target=_blank rel="noreferrer noopener nofollow">Prompt Injection 101 - Understanding Security Risks in LLM</a><img src=/svg/icons8-external-link.svg style=height:15px></li></ul><h2 id=prompt-injection-ctf>Prompt Injection CTF
<a class=anchor href=#prompt-injection-ctf>#</a></h2><ul><li><a href=https://gpa.43z.one/ target=_blank rel="noreferrer noopener nofollow">GPT Prompt Attack</a><img src=/svg/icons8-external-link.svg style=height:15px></li><li><a href=https://doublespeak.chat/ target=_blank rel="noreferrer noopener nofollow">Double Speak Chat</a><img src=/svg/icons8-external-link.svg style=height:15px></li></ul><h2 id=llm-hacker-handbook>LLM Hacker Handbook
<a class=anchor href=#llm-hacker-handbook>#</a></h2><ul><li><a href=https://doublespeak.chat/#/handbook target=_blank rel="noreferrer noopener nofollow">https://doublespeak.chat/#/handbook</a><img src=/svg/icons8-external-link.svg style=height:15px></li></ul><h2 id=videos>Videos
<a class=anchor href=#videos>#</a></h2><ul><li><a href="https://www.youtube.com/watch?v=engR9tYSsug" target=_blank rel="noreferrer noopener nofollow">AI Hacking üî• OWASP Top 10 Vulnerabilities in LLM Applications</a><img src=/svg/icons8-external-link.svg style=height:15px></li><li><a href="https://www.youtube.com/watch?v=WVOoDGzwdLU" target=_blank rel="noreferrer noopener nofollow">Fredrik Heiding - Devising and Detecting Phishing: Large Language Models vs. Smaller Human Models</a><img src=/svg/icons8-external-link.svg style=height:15px></li><li><a href="https://www.youtube.com/watch?v=Jt2d3XA07ig" target=_blank rel="noreferrer noopener nofollow">Daniel Miessler and Rez0: Hacking with AI (Ep. 24)</a><img src=/svg/icons8-external-link.svg style=height:15px></li><li><a href="https://www.youtube.com/watch?v=zY7dz4Dx5tc" target=_blank rel="noreferrer noopener nofollow">AI and hacking - opportunities and threats - Joseph ‚Äúrez0‚Äù Thacker</a><img src=/svg/icons8-external-link.svg style=height:15px></li></ul><h2 id=ai-attack-surface-map>AI Attack Surface Map
<a class=anchor href=#ai-attack-surface-map>#</a></h2><ul><li><a href=https://danielmiessler.com/p/the-ai-attack-surface-map-v1-0/ target=_blank rel="noreferrer noopener nofollow">The AI Attack Surface Map v1.0</a><img src=/svg/icons8-external-link.svg style=height:15px></li></ul><h2 id=research-papers>Research Papers
<a class=anchor href=#research-papers>#</a></h2><ul><li><a href=https://arxiv.org/abs/2306.05499 target=_blank rel="noreferrer noopener nofollow">Prompt Injection attack against LLM-integrated Applications</a><img src=/svg/icons8-external-link.svg style=height:15px></li><li><a href=https://arxiv.org/abs/2302.05733 target=_blank rel="noreferrer noopener nofollow">Exploiting Programmatic Behavior of LLMs: Dual-Use Through Standard Security Attacks</a><img src=/svg/icons8-external-link.svg style=height:15px></li><li><a href=https://llm-attacks.org/ target=_blank rel="noreferrer noopener nofollow">Universal and Transferable Adversarial Attacks on Aligned Language Models</a><img src=/svg/icons8-external-link.svg style=height:15px></li></ul></article><footer class=book-footer><div class="flex flex-wrap justify-between"><div><a class="flex align-center" href=https://github.com/payatu/cybersec-wiki/commit/b96b2ffe5eb5c65f19a2975b255d23c03f1dd61a title='Last modified by banditaditya | October 24, 2023' target=_blank rel=noopener><img src=/svg/calendar.svg class=book-icon alt=Calendar>
<span>October 24, 2023</span></a></div><div><a class="flex align-center" href=https://github.com/payatu/cybersec-wiki/edit/main/content/docs/machine-learning/learning.md target=_blank rel=noopener><img src=/svg/edit.svg class=book-icon alt=Edit>
<span>Edit this page</span></a></div></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><ul><li><a href=#contents>Contents</a></li><li><a href=#owasp-top-10-for-large-language-model-applications>OWASP Top 10 for Large Language Model Applications</a></li><li><a href=#prompt-injection-articles>Prompt Injection Articles</a></li><li><a href=#prompt-injection-videos>Prompt Injection Videos</a></li><li><a href=#prompt-injection-ctf>Prompt Injection CTF</a></li><li><a href=#llm-hacker-handbook>LLM Hacker Handbook</a></li><li><a href=#videos>Videos</a></li><li><a href=#ai-attack-surface-map>AI Attack Surface Map</a></li><li><a href=#research-papers>Research Papers</a></li></ul></li></ul></nav></div></aside></main></body></html>